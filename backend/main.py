from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import os
import numpy as np
import torch
import pandas as pd
from .models_loader import download_model
from .investment_optimizer import optimize_investment
from ml.advanced_transformer import TransformerForecast

# Load .env
load_dotenv()
print("Loaded Supabase key?", os.environ.get("SUPABASE_KEY") is not None)
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

MODEL_PATH = "models/transformer_forecast.pt"

@app.on_event("startup")
async def startup_event():
    print("Starting EnergySphere backend...")
    download_model()
    print("✅ Model ready for inference.")

@app.get("/")
async def root():
    return {"message": "EnergySphere backend running with real AI model!"}

@app.get("/predict")
async def predict_forecast():
    """Generate 24-hour forecast using the Transformer model"""
    try:
        # Load model
        model = TransformerForecast()
        model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device("cpu")))
        model.eval()

        # Generate synthetic input
        solar = np.linspace(40, 80, 24)
        wind = np.linspace(20, 60, 24)
        demand = solar * 0.3 + wind * 0.5 + np.random.randn(24) * 5
        test_data = np.stack([solar, wind, demand], axis=1)
        X = torch.tensor(test_data, dtype=torch.float32).unsqueeze(0)

        # Predict next 24-hour demand
        with torch.no_grad():
            output = model(X)
            forecast = output.squeeze().tolist()

        return {"forecast": forecast, "status": "✅ Generated by AI Transformer"}
    except Exception as e:
        return {"error": str(e)}

@app.post("/invest")
async def post_investment():
    roi = np.array([0.1, 0.15, 0.12])
    risk = np.array([0.05, 0.1, 0.07])
    budget = 1000
    allocation = optimize_investment(roi, risk, budget)
    return {"allocation": allocation.tolist()}
