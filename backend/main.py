from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import os
import numpy as np
import torch
import pandas as pd
from .models_loader import download_model
from .investment_optimizer import optimize_investment
from ml.advanced_transformer import TransformerForecast

# Load .env
load_dotenv()
print("Loaded Supabase key?", os.environ.get("SUPABASE_KEY") is not None)
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

MODEL_PATH = "models/transformer_forecast.pt"

@app.on_event("startup")
async def startup_event():
    print("Starting EnergySphere backend...")
    download_model()
    print("✅ Model ready for inference.")

@app.get("/")
async def root():
    return {"message": "EnergySphere backend running with real AI model!"}

@app.get("/predict")
async def predict_forecast():
    """Generate a clean 24-hour forecast using recursive next-step predictions."""
    try:
        model = TransformerForecast()
        model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device("cpu")))
        model.eval()

        # ----- Base synthetic input -----
        solar = np.linspace(40, 80, 24)
        wind = np.linspace(20, 60, 24)
        demand = solar * 0.3 + wind * 0.5 + np.random.randn(24) * 5

        test_data = np.stack([solar, wind, demand], axis=1)
        x_seq = torch.tensor(test_data, dtype=torch.float32).unsqueeze(0)

        forecast = []

        for _ in range(24):
            with torch.no_grad():
                pred = model(x_seq).item()  # this is a FLOAT, no indexing needed

            # store forecast
            pred = float(pred)
            pred = max(pred, 0)            # keep demand positive
            forecast.append(pred)

            # generate next input row
            next_solar = float(np.random.uniform(40, 80))
            next_wind = float(np.random.uniform(20, 60))
            next_row = torch.tensor([[next_solar, next_wind, pred]], dtype=torch.float32)

            # update window (drop oldest row, append new one)
            x_seq = torch.cat([x_seq[:, 1:, :], next_row.unsqueeze(0)], dim=1)
        # scale up raw model predictions into realistic energy demand ranges
        forecast = [(v * 150) + 200 for v in forecast]
        return {
            "forecast": forecast,
            "status": "✅ Generated by AI Transformer"
        }

    except Exception as e:
        return {"error": str(e)}


@app.post("/invest")
async def post_investment():
    roi = np.array([0.1, 0.15, 0.12])
    risk = np.array([0.05, 0.1, 0.07])
    budget = 1000
    allocation = optimize_investment(roi, risk, budget)
    return {"allocation": allocation.tolist()}
